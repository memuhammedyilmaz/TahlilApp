//
//  TesseractOCRService.swift
//  TahlilAI
//
//  Created by Muhammed YÄ±lmaz on 8.08.2025.
//

import Foundation
import UIKit
import Vision

class TesseractOCRService {
    static let shared = TesseractOCRService()
    
    private init() {}
    
    func extractText(from image: UIImage, completion: @escaping (Result<String, Error>) -> Void) {
        print("ğŸ” Tesseract OCR Analizi BaÅŸlatÄ±lÄ±yor...")
        
        guard let cgImage = image.cgImage else {
            completion(.failure(OCRError.imageConversionFailed))
            return
        }
        
        // Vision framework kullanarak OCR
        let request = VNRecognizeTextRequest { request, error in
            if let error = error {
                print("âŒ OCR HatasÄ±: \(error.localizedDescription)")
                completion(.failure(error))
                return
            }
            
            guard let observations = request.results as? [VNRecognizedTextObservation] else {
                print("âŒ OCR sonuÃ§larÄ± alÄ±namadÄ±")
                completion(.failure(OCRError.noResults))
                return
            }
            
            var extractedText = ""
            
            for observation in observations {
                guard let topCandidate = observation.topCandidates(1).first else { continue }
                extractedText += topCandidate.string + "\n"
            }
            
            print("âœ… OCR Analiz TamamlandÄ±:")
            print("ğŸ“„ Ã‡Ä±karÄ±lan Metin:")
            print(extractedText)
            print(String(repeating: "=", count: 50))
            
            if extractedText.isEmpty {
                completion(.failure(OCRError.noTextFound))
            } else {
                completion(.success(extractedText))
            }
        }
        
        // TÃ¼rkÃ§e dil desteÄŸi
        request.recognitionLanguages = ["tr-TR", "en-US"]
        request.recognitionLevel = .accurate
        request.usesLanguageCorrection = true
        
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        
        DispatchQueue.global(qos: .userInitiated).async {
            do {
                try handler.perform([request])
            } catch {
                print("âŒ OCR Ä°ÅŸlemi HatasÄ±: \(error.localizedDescription)")
                DispatchQueue.main.async {
                    completion(.failure(error))
                }
            }
        }
    }
}

enum OCRError: Error, LocalizedError {
    case imageConversionFailed
    case noResults
    case noTextFound
    
    var errorDescription: String? {
        switch self {
        case .imageConversionFailed:
            return "GÃ¶rÃ¼ntÃ¼ dÃ¶nÃ¼ÅŸtÃ¼rme hatasÄ±"
        case .noResults:
            return "OCR sonuÃ§larÄ± alÄ±namadÄ±"
        case .noTextFound:
            return "GÃ¶rÃ¼ntÃ¼de metin bulunamadÄ±"
        }
    }
}
